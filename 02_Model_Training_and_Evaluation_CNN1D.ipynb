{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94ac6b57",
   "metadata": {},
   "source": [
    "# 02 — Model Training and Evaluation — CNN1D\n",
    "\n",
    "This notebook loads preprocessed data and trains a moderate 1D CNN on sequences of shape (128, 2). It adheres to the plotting and evaluation standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c4c6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports, style, seed, GPU check, and paths\n",
    "import os, pickle, numpy as np, random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.keras import TqdmCallback\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print('GPU detected:' if gpus else 'No GPU detected by TensorFlow.', gpus)\n",
    "\n",
    "PROJECT_ROOT_PATH = '/content/drive/MyDrive/DTVT_IUH_2025/AMC_RML2016_10b/'\n",
    "PROCESSED_DATA_PATH = os.path.join(PROJECT_ROOT_PATH, 'data/')\n",
    "PREPROCESSING_OBJECTS_PATH = os.path.join(PROJECT_ROOT_PATH, 'preprocessing_objects/')\n",
    "MODEL_SAVE_PATH = os.path.join(PROJECT_ROOT_PATH, 'models/', 'CNN1D/')\n",
    "MODEL_VISUALIZATIONS_PATH = os.path.join(MODEL_SAVE_PATH, 'visualizations/')\n",
    "for d in [MODEL_SAVE_PATH, MODEL_VISUALIZATIONS_PATH]: os.makedirs(d, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dfb4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Drive mount (for Colab) and data validation\n",
    "try:\n",
    "    from google.colab import drive  # type: ignore\n",
    "    drive.mount('/content/drive')\n",
    "    print('Google Drive mounted at /content/drive')\n",
    "except Exception as e:\n",
    "    print('Not running in Colab or mount skipped. Proceeding with local filesystem. Reason:', str(e))\n",
    "    # If running locally, ensure PROJECT_ROOT_PATH is correct or override via environment variable if needed.\n",
    "\n",
    "# Ensure model directories exist (already created above); validate data/preprocessing files exist\n",
    "required_npy = [\n",
    "    'X_train_1d.npy','X_val_1d.npy','X_test_1d.npy',\n",
    "    'y_train.npy','y_val.npy','y_test.npy',\n",
    "    'snr_train.npy','snr_val.npy','snr_test.npy'\n",
    " ]\n",
    "required_pkl = ['label_encoder.pkl','standard_scaler.pkl']\n",
    "\n",
    "missing = []\n",
    "for fname in required_npy:\n",
    "    if not os.path.exists(os.path.join(PROCESSED_DATA_PATH, fname)):\n",
    "        missing.append(os.path.join(PROCESSED_DATA_PATH, fname))\n",
    "for fname in required_pkl:\n",
    "    if not os.path.exists(os.path.join(PREPROCESSING_OBJECTS_PATH, fname)):\n",
    "        missing.append(os.path.join(PREPROCESSING_OBJECTS_PATH, fname))\n",
    "\n",
    "if missing:\n",
    "    print('Missing required files:')\n",
    "    for m in missing: print(' -', m)\n",
    "    raise FileNotFoundError('Preprocessed data not found. Please run 01_Data_Preparation_and_Visualization.ipynb to generate datasets and preprocessing objects.')\n",
    "else:\n",
    "    print('All required data/preprocessing files found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7f77a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 1D data and preprocessing objects\n",
    "X_train = np.load(os.path.join(PROCESSED_DATA_PATH, 'X_train_1d.npy'))\n",
    "X_val = np.load(os.path.join(PROCESSED_DATA_PATH, 'X_val_1d.npy'))\n",
    "X_test = np.load(os.path.join(PROCESSED_DATA_PATH, 'X_test_1d.npy'))\n",
    "y_train = np.load(os.path.join(PROCESSED_DATA_PATH, 'y_train.npy'))\n",
    "y_val = np.load(os.path.join(PROCESSED_DATA_PATH, 'y_val.npy'))\n",
    "y_test = np.load(os.path.join(PROCESSED_DATA_PATH, 'y_test.npy'))\n",
    "snr_train = np.load(os.path.join(PROCESSED_DATA_PATH, 'snr_train.npy'))\n",
    "snr_val = np.load(os.path.join(PROCESSED_DATA_PATH, 'snr_val.npy'))\n",
    "snr_test = np.load(os.path.join(PROCESSED_DATA_PATH, 'snr_test.npy'))\n",
    "\n",
    "with open(os.path.join(PREPROCESSING_OBJECTS_PATH, 'label_encoder.pkl'), 'rb') as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "with open(os.path.join(PREPROCESSING_OBJECTS_PATH, 'standard_scaler.pkl'), 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "num_classes = y_train.shape[1]\n",
    "input_shape = X_train.shape[1:]\n",
    "print('Shapes:', X_train.shape, X_val.shape, X_test.shape, '| Classes:', num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6e6f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a moderate 1D CNN\n",
    "def build_cnn1d(input_shape, num_classes):\n",
    "    \"\"\"Build a moderate-depth 1D CNN for AMC.\"\"\"\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = layers.Conv1D(32, 5, padding='same', activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv1D(64, 5, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "    x = layers.Conv1D(128, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = keras.Model(inputs, outputs, name='CNN1D_AMC')\n",
    "    return model\n",
    "\n",
    "model = build_cnn1d(input_shape, num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6aec72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile, callbacks, and train with tqdm\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.008)\n",
    "model.compile(optimizer=optimizer, loss=keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "ckpt_path = os.path.join(MODEL_SAVE_PATH, 'best_model.keras')\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(ckpt_path, monitor='val_loss', save_best_only=True, save_weights_only=False),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1),\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=1024,\n",
    "    callbacks=[TqdmCallback(verbose=0)] + callbacks,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b493c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload best model (safeguard)\n",
    "best_model = keras.models.load_model(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4b64a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history (save then show)\n",
    "def plot_history(hist, prefix='cnn1d'):\n",
    "    hist_dict = hist.history\n",
    "    # Accuracy\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(hist_dict['accuracy'], label='train_acc')\n",
    "    plt.plot(hist_dict['val_accuracy'], label='val_acc')\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(MODEL_VISUALIZATIONS_PATH, f'{prefix}_history_accuracy.png'), dpi=300)\n",
    "    plt.show()\n",
    "    # Loss\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(hist_dict['loss'], label='train_loss')\n",
    "    plt.plot(hist_dict['val_loss'], label='val_loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(MODEL_VISUALIZATIONS_PATH, f'{prefix}_history_loss.png'), dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history, prefix='cnn1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adcb422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {test_loss:.4f} | Test accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9a3688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions and classification report\n",
    "y_pred_probs = best_model.predict(X_test, verbose=0)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "class_names = label_encoder.classes_.tolist()\n",
    "report = classification_report(y_true, y_pred, target_names=class_names, digits=3)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c154a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy heatmap by (mod x SNR)\n",
    "snrs_unique = np.sort(np.unique(snr_test))\n",
    "acc_matrix = np.zeros((len(class_names), len(snrs_unique)))\n",
    "for j, s in enumerate(snrs_unique):\n",
    "    idx = np.where(snr_test == s)[0]\n",
    "    if len(idx) == 0: continue\n",
    "    yt = y_true[idx]; yp = y_pred[idx]\n",
    "    for i, cname in enumerate(class_names):\n",
    "        cls = i\n",
    "        mask = (yt == cls)\n",
    "        denom = np.sum(mask)\n",
    "        acc_matrix[i, j] = (np.sum((yp == cls) & mask) / denom) if denom > 0 else np.nan\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(acc_matrix, annot=True, fmt='.3f', cmap='magma', cbar=True, square=True, linewidths=0.5, linecolor='white', xticklabels=snrs_unique, yticklabels=class_names)\n",
    "plt.title('Per-Class Accuracy vs SNR')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('Modulation')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_VISUALIZATIONS_PATH, 'accuracy_heatmap.png'), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4ec11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall confusion matrices (raw and normalized)\n",
    "cm = confusion_matrix(y_true, y_pred, labels=np.arange(len(class_names)))\n",
    "cm_norm = cm / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "per_class_total = cm.sum(axis=1)\n",
    "vmax_raw = per_class_total.max() if per_class_total.size>0 else None\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16,6))\n",
    "sns.heatmap(cm, ax=axes[0], cmap='magma', annot=True, fmt='d', cbar=True, square=True, linewidths=0.5, linecolor='white', vmin=0, vmax=vmax_raw)\n",
    "axes[0].set_title('Confusion Matrix — Raw Counts')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('True')\n",
    "axes[0].set_xticklabels(class_names, rotation=90)\n",
    "axes[0].set_yticklabels(class_names, rotation=0)\n",
    "\n",
    "sns.heatmap(cm_norm, ax=axes[1], cmap='magma', annot=True, fmt='.3f', cbar=True, square=True, linewidths=0.5, linecolor='white', vmin=0.0, vmax=1.0)\n",
    "axes[1].set_title('Confusion Matrix — Normalized')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('True')\n",
    "axes[1].set_xticklabels(class_names, rotation=90)\n",
    "axes[1].set_yticklabels(class_names, rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_VISUALIZATIONS_PATH, 'confusion_matrices_overall.png'), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d95872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices per SNR with fixed colorbars\n",
    "snrs_unique = np.sort(np.unique(snr_test))\n",
    "class_count_per_snr = None\n",
    "for s in snrs_unique:\n",
    "    idx = np.where(snr_test == s)[0]\n",
    "    if len(idx)==0: continue\n",
    "    yt = y_true[idx]; yp = y_pred[idx]\n",
    "    cm_s = confusion_matrix(yt, yp, labels=np.arange(len(class_names)))\n",
    "    cm_s_norm = cm_s / cm_s.sum(axis=1, keepdims=True)\n",
    "    # vmin/vmax: fix across SNRs based on per-class count at this SNR\n",
    "    per_class_total_s = cm_s.sum(axis=1)\n",
    "    vmax_raw_s = per_class_total_s.max() if per_class_total_s.size>0 else None\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16,6))\n",
    "    sns.heatmap(cm_s, ax=axes[0], cmap='magma', annot=True, fmt='d', cbar=True, square=True, linewidths=0.5, linecolor='white', vmin=0, vmax=vmax_raw_s)\n",
    "    axes[0].set_title(f'Confusion (Raw) — SNR {s} dB')\n",
    "    axes[0].set_xlabel('Predicted')\n",
    "    axes[0].set_ylabel('True')\n",
    "    axes[0].set_xticklabels(class_names, rotation=90)\n",
    "    axes[0].set_yticklabels(class_names, rotation=0)\n",
    "    sns.heatmap(cm_s_norm, ax=axes[1], cmap='magma', annot=True, fmt='.3f', cbar=True, square=True, linewidths=0.5, linecolor='white', vmin=0.0, vmax=1.0)\n",
    "    axes[1].set_title(f'Confusion (Normalized) — SNR {s} dB')\n",
    "    axes[1].set_xlabel('Predicted')\n",
    "    axes[1].set_ylabel('True')\n",
    "    axes[1].set_xticklabels(class_names, rotation=90)\n",
    "    axes[1].set_yticklabels(class_names, rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(MODEL_VISUALIZATIONS_PATH, f'confusion_matrices_snr_{s}.png'), dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c8afdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy vs. SNR (overall and per class)\n",
    "snrs_unique = np.sort(np.unique(snr_test))\n",
    "overall_acc = []\n",
    "per_class_acc = {i: [] for i in range(len(class_names))}\n",
    "for s in snrs_unique:\n",
    "    idx = np.where(snr_test == s)[0]\n",
    "    if len(idx)==0: continue\n",
    "    yt = y_true[idx]; yp = y_pred[idx]\n",
    "    overall_acc.append(np.mean(yt == yp))\n",
    "    for i in range(len(class_names)):\n",
    "        mask = (yt == i)\n",
    "        denom = np.sum(mask)\n",
    "        per_class_acc[i].append((np.sum((yp==i)&mask)/denom) if denom>0 else np.nan)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(snrs_unique, overall_acc, marker='o', linewidth=2) \n",
    "plt.title('Overall Accuracy vs SNR')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_VISUALIZATIONS_PATH, 'overall_accuracy_vs_snr.png'), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "palette = sns.color_palette('tab10', n_colors=len(class_names))\n",
    "for i, cname in enumerate(class_names):\n",
    "    plt.plot(snrs_unique, per_class_acc[i], marker='o', label=cname, linewidth=2, color=palette[i % len(palette)])\n",
    "plt.title('Per-Class Accuracy vs SNR')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best', ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_VISUALIZATIONS_PATH, 'per_class_accuracy_vs_snr.png'), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828f9b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top confusion pairs analysis and summary\n",
    "off_diag = cm.copy(); np.fill_diagonal(off_diag, 0)\n",
    "pairs = []\n",
    "for i_true in range(off_diag.shape[0]):\n",
    "    for j_pred in range(off_diag.shape[1]):\n",
    "        if i_true != j_pred and off_diag[i_true, j_pred] > 0:\n",
    "            pairs.append((off_diag[i_true, j_pred], class_names[i_true], class_names[j_pred]))\n",
    "pairs.sort(reverse=True)\n",
    "top_pairs = pairs[:3]\n",
    "print('Top Confusion Pairs:')\n",
    "for k, (cnt, t, p) in enumerate(top_pairs, start=1):\n",
    "    print(f\"{k}. {t} → {p}: {cnt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467cdef8",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "- Overall test accuracy is printed above.\n",
    "- Training history, confusion matrices (overall and per SNR), heatmap, and accuracy vs SNR plots are saved under the model's visualizations directory.\n",
    "- Top confusion pairs are printed for quick insight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67a40f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure colormaps for heatmaps/matrices\n",
    "CMAP = 'magma'  # options: 'magma', 'viridis', 'plasma', 'cividis'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bab32c",
   "metadata": {},
   "source": [
    "## Final Results Summary\n",
    "\n",
    "- Overall test accuracy and loss have been computed above.\n",
    "- The best epoch weights were restored, and the saved `.keras` file was reloaded for evaluation.\n",
    "- Top confusion pairs (highest off-diagonal counts) are printed above for diagnostic clarity.\n",
    "\n",
    "All images and artifacts are saved under the model directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740bb351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training history for comparison overlays\n",
    "import json\n",
    "hist_json = {k: list(map(float, v)) for k, v in history.history.items()}\n",
    "with open(os.path.join(MODEL_SAVE_PATH, 'history.json'), 'w') as f:\n",
    "    json.dump(hist_json, f)\n",
    "print('Saved training history to', os.path.join(MODEL_SAVE_PATH, 'history.json'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
