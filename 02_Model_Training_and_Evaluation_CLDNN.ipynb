{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0900982b",
   "metadata": {},
   "source": [
    "# 02 — Model Training and Evaluation — CLDNN (Conv1D + LSTM)\n",
    "\n",
    "This notebook trains a CLDNN model that stacks Conv1D layers followed by a bidirectional LSTM and dense classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a49c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports, style, seed, GPU check, and paths\n",
    "import os, pickle, numpy as np, random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.keras import TqdmCallback\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print('GPU detected:' if gpus else 'No GPU detected by TensorFlow.', gpus)\n",
    "\n",
    "PROJECT_ROOT_PATH = '/content/drive/MyDrive/DTVT_IUH_2025/AMC_RML2016_10b/'\n",
    "PROCESSED_DATA_PATH = os.path.join(PROJECT_ROOT_PATH, 'data/')\n",
    "PREPROCESSING_OBJECTS_PATH = os.path.join(PROJECT_ROOT_PATH, 'preprocessing_objects/')\n",
    "MODEL_SAVE_PATH = os.path.join(PROJECT_ROOT_PATH, 'models/', 'CLDNN/')\n",
    "MODEL_VISUALIZATIONS_PATH = os.path.join(MODEL_SAVE_PATH, 'visualizations/')\n",
    "for d in [MODEL_SAVE_PATH, MODEL_VISUALIZATIONS_PATH]: os.makedirs(d, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0206ad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 1D data and preprocessing objects\n",
    "import numpy as np, os, pickle\n",
    "X_train = np.load(os.path.join(PROCESSED_DATA_PATH, 'X_train_1d.npy'))\n",
    "X_val = np.load(os.path.join(PROCESSED_DATA_PATH, 'X_val_1d.npy'))\n",
    "X_test = np.load(os.path.join(PROCESSED_DATA_PATH, 'X_test_1d.npy'))\n",
    "y_train = np.load(os.path.join(PROCESSED_DATA_PATH, 'y_train.npy'))\n",
    "y_val = np.load(os.path.join(PROCESSED_DATA_PATH, 'y_val.npy'))\n",
    "y_test = np.load(os.path.join(PROCESSED_DATA_PATH, 'y_test.npy'))\n",
    "snr_train = np.load(os.path.join(PROCESSED_DATA_PATH, 'snr_train.npy'))\n",
    "snr_val = np.load(os.path.join(PROCESSED_DATA_PATH, 'snr_val.npy'))\n",
    "snr_test = np.load(os.path.join(PROCESSED_DATA_PATH, 'snr_test.npy'))\n",
    "\n",
    "with open(os.path.join(PREPROCESSING_OBJECTS_PATH, 'label_encoder.pkl'), 'rb') as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "with open(os.path.join(PREPROCESSING_OBJECTS_PATH, 'standard_scaler.pkl'), 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "num_classes = y_train.shape[1]\n",
    "input_shape = X_train.shape[1:]\n",
    "print('Shapes:', X_train.shape, X_val.shape, X_test.shape, '| Classes:', num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017de923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CLDNN (Conv1D + LSTM)\n",
    "def build_cldnn(input_shape, num_classes):\n",
    "    \"\"\"Build a compact CLDNN: Conv1D blocks -> BiLSTM -> Dense.\"\"\"\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = layers.Conv1D(32, 5, padding='same', activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv1D(64, 5, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "    x = layers.Conv1D(128, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=False))(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = keras.Model(inputs, outputs, name='CLDNN_AMC')\n",
    "    return model\n",
    "\n",
    "model = build_cldnn(input_shape, num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec35cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile, callbacks, and train with tqdm\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.008)\n",
    "model.compile(optimizer=optimizer, loss=keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "ckpt_path = os.path.join(MODEL_SAVE_PATH, 'best_model.keras')\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(ckpt_path, monitor='val_loss', save_best_only=True, save_weights_only=False),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1),\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=1024,\n",
    "    callbacks=[TqdmCallback(verbose=0)] + callbacks,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c60d5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload best model (safeguard)\n",
    "best_model = keras.models.load_model(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07bd85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots: history, confusion matrices, heatmaps, accuracy vs SNR (same as CNN1D)\n",
    "def plot_history(hist, prefix='cldnn'):\n",
    "    hist_dict = hist.history\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(hist_dict['accuracy'], label='train_acc')\n",
    "    plt.plot(hist_dict['val_accuracy'], label='val_acc')\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(MODEL_VISUALIZATIONS_PATH, f'{prefix}_history_accuracy.png'), dpi=300)\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(hist_dict['loss'], label='train_loss')\n",
    "    plt.plot(hist_dict['val_loss'], label='val_loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(MODEL_VISUALIZATIONS_PATH, f'{prefix}_history_loss.png'), dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history, prefix='cldnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d37e889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation and reports\n",
    "test_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {test_loss:.4f} | Test accuracy: {test_acc:.4f}')\n",
    "\n",
    "y_pred_probs = best_model.predict(X_test, verbose=0)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "class_names = label_encoder.classes_.tolist()\n",
    "print(classification_report(y_true, y_pred, target_names=class_names, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203b6ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy heatmap by (mod x SNR)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "snrs_unique = np.sort(np.unique(snr_test))\n",
    "acc_matrix = np.zeros((len(class_names), len(snrs_unique)))\n",
    "for j, s in enumerate(snrs_unique):\n",
    "    idx = np.where(snr_test == s)[0]\n",
    "    if len(idx) == 0: continue\n",
    "    yt = y_true[idx]; yp = y_pred[idx]\n",
    "    for i, cname in enumerate(class_names):\n",
    "        mask = (yt == i)\n",
    "        denom = np.sum(mask)\n",
    "        acc_matrix[i, j] = (np.sum((yp == i) & mask) / denom) if denom > 0 else np.nan\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(acc_matrix, annot=True, fmt='.3f', cmap='magma', cbar=True, square=True, linewidths=0.5, linecolor='white', xticklabels=snrs_unique, yticklabels=class_names)\n",
    "plt.title('Per-Class Accuracy vs SNR')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('Modulation')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_VISUALIZATIONS_PATH, 'accuracy_heatmap.png'), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d6f6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices overall and per SNR with fixed colorbars\n",
    "cm = confusion_matrix(y_true, y_pred, labels=np.arange(len(class_names)))\n",
    "cm_norm = cm / cm.sum(axis=1, keepdims=True)\n",
    "vmax_raw = cm.sum(axis=1).max()\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16,6))\n",
    "sns.heatmap(cm, ax=axes[0], cmap='magma', annot=True, fmt='d', cbar=True, square=True, linewidths=0.5, linecolor='white', vmin=0, vmax=vmax_raw)\n",
    "axes[0].set_title('Confusion Matrix — Raw Counts')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('True')\n",
    "axes[0].set_xticklabels(class_names, rotation=90)\n",
    "axes[0].set_yticklabels(class_names, rotation=0)\n",
    "sns.heatmap(cm_norm, ax=axes[1], cmap='magma', annot=True, fmt='.3f', cbar=True, square=True, linewidths=0.5, linecolor='white', vmin=0.0, vmax=1.0)\n",
    "axes[1].set_title('Confusion Matrix — Normalized')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('True')\n",
    "axes[1].set_xticklabels(class_names, rotation=90)\n",
    "axes[1].set_yticklabels(class_names, rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_VISUALIZATIONS_PATH, 'confusion_matrices_overall.png'), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "snrs_unique = np.sort(np.unique(snr_test))\n",
    "for s in snrs_unique:\n",
    "    idx = np.where(snr_test == s)[0]\n",
    "    if len(idx)==0: continue\n",
    "    yt = y_true[idx]; yp = y_pred[idx]\n",
    "    cm_s = confusion_matrix(yt, yp, labels=np.arange(len(class_names)))\n",
    "    cm_s_norm = cm_s / cm_s.sum(axis=1, keepdims=True)\n",
    "    vmax_raw_s = cm_s.sum(axis=1).max()\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16,6))\n",
    "    sns.heatmap(cm_s, ax=axes[0], cmap='magma', annot=True, fmt='d', cbar=True, square=True, linewidths=0.5, linecolor='white', vmin=0, vmax=vmax_raw_s)\n",
    "    axes[0].set_title(f'Confusion (Raw) — SNR {s} dB')\n",
    "    axes[0].set_xlabel('Predicted')\n",
    "    axes[0].set_ylabel('True')\n",
    "    axes[0].set_xticklabels(class_names, rotation=90)\n",
    "    axes[0].set_yticklabels(class_names, rotation=0)\n",
    "    sns.heatmap(cm_s_norm, ax=axes[1], cmap='magma', annot=True, fmt='.3f', cbar=True, square=True, linewidths=0.5, linecolor='white', vmin=0.0, vmax=1.0)\n",
    "    axes[1].set_title(f'Confusion (Normalized) — SNR {s} dB')\n",
    "    axes[1].set_xlabel('Predicted')\n",
    "    axes[1].set_ylabel('True')\n",
    "    axes[1].set_xticklabels(class_names, rotation=90)\n",
    "    axes[1].set_yticklabels(class_names, rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(MODEL_VISUALIZATIONS_PATH, f'confusion_matrices_snr_{s}.png'), dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a7276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy vs SNR (overall, per class)\n",
    "snrs_unique = np.sort(np.unique(snr_test))\n",
    "y_pred = np.argmax(best_model.predict(X_test, verbose=0), axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "overall_acc = []\n",
    "per_class_acc = {i: [] for i in range(len(class_names))}\n",
    "for s in snrs_unique:\n",
    "    idx = np.where(snr_test == s)[0]\n",
    "    if len(idx)==0: continue\n",
    "    yt = y_true[idx]; yp = y_pred[idx]\n",
    "    overall_acc.append(np.mean(yt == yp))\n",
    "    for i in range(len(class_names)):\n",
    "        mask = (yt == i)\n",
    "        denom = np.sum(mask)\n",
    "        per_class_acc[i].append((np.sum((yp==i)&mask)/denom) if denom>0 else np.nan)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(snrs_unique, overall_acc, marker='o', linewidth=2) \n",
    "plt.title('Overall Accuracy vs SNR')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_VISUALIZATIONS_PATH, 'overall_accuracy_vs_snr.png'), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "palette = sns.color_palette('tab10', n_colors=len(class_names))\n",
    "for i, cname in enumerate(class_names):\n",
    "    plt.plot(snrs_unique, per_class_acc[i], marker='o', label=cname, linewidth=2, color=palette[i % len(palette)])\n",
    "plt.title('Per-Class Accuracy vs SNR')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best', ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_VISUALIZATIONS_PATH, 'per_class_accuracy_vs_snr.png'), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422f9a45",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "Artifacts and plots are saved. See the confusion matrices, accuracy curves, and heatmaps for performance diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043a39d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure colormaps for heatmaps/matrices\n",
    "CMAP = 'magma'  # options: 'magma', 'viridis', 'plasma', 'cividis'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0ca00d",
   "metadata": {},
   "source": [
    "## Final Results Summary\n",
    "\n",
    "- Test accuracy/loss printed above.\n",
    "- Confusion matrices (overall and per-SNR), heatmaps, and accuracy curves are saved.\n",
    "- The best `.keras` model file is available under the model directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fba49b7",
   "metadata": {},
   "source": [
    "## Comparative Analysis: CNN1D vs CLDNN\n",
    "\n",
    "This section loads the CNN1D best model and compares it to the current CLDNN on the same test set: overall accuracy, per-class accuracy vs SNR, and top confusion pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47912749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CNN1D model and compare against CLDNN\n",
    "import os, numpy as np, seaborn as sns, matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cnn1d_path = os.path.join(PROJECT_ROOT_PATH, 'models', 'CNN1D', 'best_model.keras')\n",
    "if os.path.exists(cnn1d_path):\n",
    "    cnn1d_best = keras.models.load_model(cnn1d_path)\n",
    "    y_pred_cnn = np.argmax(cnn1d_best.predict(X_test, verbose=0), axis=1)\n",
    "    y_pred_cld = np.argmax(best_model.predict(X_test, verbose=0), axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    # Overall accuracy\n",
    "    acc_cnn = float(np.mean(y_pred_cnn == y_true))\n",
    "    acc_cld = float(np.mean(y_pred_cld == y_true))\n",
    "    print(f'CNN1D Test Accuracy: {acc_cnn:.4f}')\n",
    "    print(f'CLDNN Test Accuracy: {acc_cld:.4f}')\n",
    "    # Per-class accuracy vs SNR\n",
    "    snrs_unique = np.sort(np.unique(snr_test))\n",
    "    per_class_acc_cnn = np.zeros((len(class_names), len(snrs_unique)))\n",
    "    per_class_acc_cld = np.zeros((len(class_names), len(snrs_unique)))\n",
    "    for j, s in enumerate(snrs_unique):\n",
    "        idx = np.where(snr_test == s)[0]\n",
    "        yt = y_true[idx]\n",
    "        ypc = y_pred_cnn[idx]\n",
    "        ypl = y_pred_cld[idx]\n",
    "        for i in range(len(class_names)):\n",
    "            mask = (yt == i)\n",
    "            denom = mask.sum()\n",
    "            per_class_acc_cnn[i, j] = ((ypc==i)&mask).sum()/denom if denom>0 else np.nan\n",
    "            per_class_acc_cld[i, j] = ((ypl==i)&mask).sum()/denom if denom>0 else np.nan\n",
    "    plt.figure(figsize=(12,6))\n",
    "    diff = per_class_acc_cnn - per_class_acc_cld\n",
    "    sns.heatmap(diff, annot=True, fmt='.3f', cmap=CMAP, square=True, linewidths=0.5, linecolor='white', xticklabels=snrs_unique, yticklabels=class_names)\n",
    "    plt.title('Accuracy Difference (CNN1D - CLDNN) per Class vs SNR')\n",
    "    plt.xlabel('SNR (dB)')\n",
    "    plt.ylabel('Modulation')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(MODEL_VISUALIZATIONS_PATH, 'comparison_accuracy_diff_heatmap.png'), dpi=300)\n",
    "    plt.show()\n",
    "    # Top confusion pairs\n",
    "    def top_pairs(cm, k=3):\n",
    "        off = cm.copy(); np.fill_diagonal(off, 0)\n",
    "        pairs = []\n",
    "        for i in range(off.shape[0]):\n",
    "            for j in range(off.shape[1]):\n",
    "                if i!=j and off[i,j]>0:\n",
    "                    pairs.append((off[i,j], class_names[i], class_names[j]))\n",
    "        pairs.sort(reverse=True)\n",
    "        return pairs[:k]\n",
    "    cm_cnn = confusion_matrix(y_true, y_pred_cnn, labels=np.arange(len(class_names)))\n",
    "    cm_cld = confusion_matrix(y_true, y_pred_cld, labels=np.arange(len(class_names)))\n",
    "    print('Top Confusions — CNN1D:', top_pairs(cm_cnn))\n",
    "    print('Top Confusions — CLDNN:', top_pairs(cm_cld))\n",
    "else:\n",
    "    print('CNN1D model file not found; run the CNN1D notebook first to enable comparison.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30387f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training history for comparison overlays\n",
    "import json\n",
    "hist_json = {k: list(map(float, v)) for k, v in history.history.items()}\n",
    "with open(os.path.join(MODEL_SAVE_PATH, 'history.json'), 'w') as f:\n",
    "    json.dump(hist_json, f)\n",
    "print('Saved training history to', os.path.join(MODEL_SAVE_PATH, 'history.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81506ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay training curves: CNN1D vs CLDNN\n",
    "cnn_hist_path = os.path.join(PROJECT_ROOT_PATH, 'models', 'CNN1D', 'history.json')\n",
    "cld_hist_path = os.path.join(MODEL_SAVE_PATH, 'history.json')\n",
    "if os.path.exists(cnn_hist_path) and os.path.exists(cld_hist_path):\n",
    "    import json\n",
    "    with open(cnn_hist_path, 'r') as f: cnn_hist = json.load(f)\n",
    "    with open(cld_hist_path, 'r') as f: cld_hist = json.load(f)\n",
    "    # Accuracy overlay\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(cnn_hist.get('accuracy', []), label='CNN1D train_acc', linewidth=2)\n",
    "    plt.plot(cnn_hist.get('val_accuracy', []), label='CNN1D val_acc', linewidth=2)\n",
    "    plt.plot(cld_hist.get('accuracy', []), label='CLDNN train_acc', linewidth=2)\n",
    "    plt.plot(cld_hist.get('val_accuracy', []), label='CLDNN val_acc', linewidth=2)\n",
    "    plt.title('Training Accuracy — CNN1D vs CLDNN')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(MODEL_VISUALIZATIONS_PATH, 'overlay_accuracy.png'), dpi=300)\n",
    "    plt.show()\n",
    "    # Loss overlay\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(cnn_hist.get('loss', []), label='CNN1D train_loss', linewidth=2)\n",
    "    plt.plot(cnn_hist.get('val_loss', []), label='CNN1D val_loss', linewidth=2)\n",
    "    plt.plot(cld_hist.get('loss', []), label='CLDNN train_loss', linewidth=2)\n",
    "    plt.plot(cld_hist.get('val_loss', []), label='CLDNN val_loss', linewidth=2)\n",
    "    plt.title('Training Loss — CNN1D vs CLDNN')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(MODEL_VISUALIZATIONS_PATH, 'overlay_loss.png'), dpi=300)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Overlay skipped: history.json missing. Run both model trainings to generate.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fe8c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Who-wins heatmap: sign(cnn - cld) over (class × SNR)\n",
    "if 'per_class_acc_cnn' in locals() and 'per_class_acc_cld' in locals():\n",
    "    sign_mat = np.sign(per_class_acc_cnn - per_class_acc_cld)\n",
    "    # Map to -1, 0, +1; keep NaN as-is\n",
    "    plt.figure(figsize=(12,6))\n",
    "    ax = sns.heatmap(sign_mat, annot=False, cmap=CMAP, square=True, linewidths=0.5, linecolor='white', vmin=-1, vmax=1, xticklabels=snrs_unique, yticklabels=class_names, cbar=True)\n",
    "    plt.title('Who Wins per Class × SNR (sign: +1 CNN1D, -1 CLDNN, 0 tie)')\n",
    "    plt.xlabel('SNR (dB)')\n",
    "    plt.ylabel('Modulation')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(MODEL_VISUALIZATIONS_PATH, 'who_wins_heatmap.png'), dpi=300)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Who-wins heatmap skipped: per-class accuracy arrays not available. Run comparison cell first.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6768d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Accuracy vs SNR — CNN1D vs CLDNN on one chart\n",
    "if 'y_pred_cnn' in locals() and 'y_pred_cld' in locals():\n",
    "    snrs_plot = np.sort(np.unique(snr_test))\n",
    "    overall_cnn, overall_cld = [], []\n",
    "    for s in snrs_plot:\n",
    "        idx = np.where(snr_test == s)[0]\n",
    "        if len(idx) == 0:\n",
    "            overall_cnn.append(np.nan)\n",
    "            overall_cld.append(np.nan)\n",
    "            continue\n",
    "        yt = y_true[idx]\n",
    "        overall_cnn.append(np.mean(y_pred_cnn[idx] == yt))\n",
    "        overall_cld.append(np.mean(y_pred_cld[idx] == yt))\n",
    "    plt.figure(figsize=(12,4))\n",
    "    palette = sns.color_palette('tab10', n_colors=2)\n",
    "    plt.plot(snrs_plot, overall_cnn, marker='o', linewidth=2, label='CNN1D', color=palette[0])\n",
    "    plt.plot(snrs_plot, overall_cld, marker='s', linewidth=2, label='CLDNN', color=palette[1])\n",
    "    plt.title('Overall Accuracy vs SNR — CNN1D vs CLDNN')\n",
    "    plt.xlabel('SNR (dB)')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(MODEL_VISUALIZATIONS_PATH, 'overall_accuracy_vs_snr_both_models.png'), dpi=300)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Overall accuracy comparison skipped: predictions for both models not available. Run the comparison cell first.')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
